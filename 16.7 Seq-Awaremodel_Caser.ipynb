{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import zipfile\n",
    "from urllib import request\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, user_ids, item_ids, L, num_users, num_items, candidates):\n",
    "        user_ids, item_ids = np.array(user_ids), np.array(item_ids)\n",
    "        sort_idx = np.array(sorted(range(len(user_ids)),\n",
    "                                    key=lambda k: user_ids[k]))\n",
    "        u_ids, i_ids = user_ids[sort_idx], item_ids[sort_idx]\n",
    "        temp, u_ids, self.cand = {}, np.array(u_ids), candidates\n",
    "        self.all_items = set([i for i in range(num_items)])\n",
    "        [temp.setdefault(u_ids[i], []).append(i) for i, _ in enumerate(u_ids)]\n",
    "        temp = sorted(temp.items(), key=lambda x: x[0])\n",
    "        u_ids = np.array([i[0] for i in temp])\n",
    "        idx = np.array([i[1][0] for i in temp])\n",
    "        self.ns = ns = int(sum([c - L if c >= L + 1 else 1 for c\n",
    "                                in np.array([len(i[1]) for i in temp])]))\n",
    "        self.seq_items = np.zeros((ns, L))\n",
    "        self.seq_users = np.zeros(ns, dtype='int32')\n",
    "        self.seq_tgt = np.zeros((ns, 1))\n",
    "        self.test_seq = np.zeros((num_users, L))\n",
    "        test_users, _uid = np.empty(num_users), None\n",
    "        for i, (uid, i_seq) in enumerate(self._seq(u_ids, i_ids, idx, L + 1)):\n",
    "            if uid != _uid:\n",
    "                self.test_seq[uid][:] = i_seq[-L:]\n",
    "                test_users[uid], _uid = uid, uid\n",
    "            self.seq_tgt[i][:] = i_seq[-1:]\n",
    "            self.seq_items[i][:], self.seq_users[i] = i_seq[:L], uid\n",
    "\n",
    "    def _win(self, tensor, window_size, step_size=1):\n",
    "        if len(tensor) - window_size >= 0:\n",
    "            for i in range(len(tensor), 0, - step_size):\n",
    "                if i - window_size >= 0:\n",
    "                    yield tensor[i - window_size:i]\n",
    "                else:\n",
    "                    break\n",
    "        else:\n",
    "            yield tensor\n",
    "\n",
    "    def _seq(self, u_ids, i_ids, idx, max_len):\n",
    "        for i in range(len(idx)):\n",
    "            stop_idx = None if i >= len(idx) - 1 else int(idx[i + 1])\n",
    "            for s in self._win(i_ids[int(idx[i]):stop_idx], max_len):\n",
    "                yield (int(u_ids[i]), s)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ns\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        neg = list(self.all_items - set(self.cand[int(self.seq_users[idx])]))\n",
    "        i = random.randint(0, len(neg) - 1)\n",
    "        # user id, time step 만큼의 items, target item, neg item\n",
    "        return (int(self.seq_users[idx]), torch.tensor(self.seq_items[idx]), int(self.seq_tgt[idx][0]),\n",
    "                neg[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ml100k():\n",
    "    # download\n",
    "    url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "    savename = \"ml-100k.zip\"\n",
    "    request.urlretrieve(url, savename)\n",
    "    print('Complete!')\n",
    "    # unzip\n",
    "    file_name = os.path.join('./', savename)\n",
    "    file_zip = zipfile.ZipFile(file_name)\n",
    "    file_zip.extractall('./')\n",
    "    file_zip.close()\n",
    "\n",
    "def read_data_ml100k():\n",
    "    \"\"\"\n",
    "    데이터를 다운받고, dataframe형태의 data, user id목록, itme id 목록 반환\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(os.path.join('./ml-100k/', 'u.data')):\n",
    "        print('Download ...')\n",
    "        download_ml100k()\n",
    "    names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(os.path.join('./ml-100k/', 'u.data'), '\\t', names=names,\n",
    "                       engine='python')\n",
    "    num_users = data.user_id.unique().shape[0]\n",
    "    num_items = data.item_id.unique().shape[0]\n",
    "    return data, num_users, num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_ml100k(data, num_users, num_items, feedback='explicit'):\n",
    "    \"\"\"\n",
    "    과정은 정확히 이해안되는데 user id, item id, score, 유저-아이템 행렬 반환\n",
    "    explicit 일때는 유저 아이템 행렬\n",
    "    implicit 일때는 key : 유저, val : 아이템 리스트 인 dict \n",
    "    \"\"\"\n",
    "    users, items, scores = [], [], []\n",
    "    inter = np.zeros((num_items, num_users)) if feedback == 'explicit' else {}\n",
    "    for line in data.itertuples():\n",
    "        user_index, item_index = int(line[1] - 1), int(line[2] - 1)\n",
    "        score = int(line[3]) if feedback == 'explicit' else 1\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "        if feedback == 'implicit':\n",
    "            inter.setdefault(user_index, []).append(item_index)\n",
    "        else:\n",
    "            inter[item_index, user_index] = score\n",
    "    return users, items, scores, inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_ml100k(data, num_users, num_items,\n",
    "                      split_mode='random', test_ratio=0.1):\n",
    "    \"\"\"Split the dataset in random mode or seq-aware mode.\"\"\"\n",
    "    if split_mode == 'seq-aware':\n",
    "        train_items, test_items, train_list = {}, {}, []\n",
    "        for line in data.itertuples():\n",
    "            u, i, rating, time = line[1], line[2], line[3], line[4]\n",
    "            train_items.setdefault(u, []).append((u, i, rating, time))\n",
    "            if u not in test_items or test_items[u][-1] < time:\n",
    "                test_items[u] = (i, rating, time)\n",
    "        for u in range(1, num_users + 1):\n",
    "            train_list.extend(sorted(train_items[u], key=lambda k: k[3]))\n",
    "        test_data = [(key, *value) for key, value in test_items.items()]\n",
    "        train_data = [item for item in train_list if item not in test_data]\n",
    "        train_data = pd.DataFrame(train_data)\n",
    "        test_data = pd.DataFrame(test_data)\n",
    "    else:\n",
    "        mask = [True if x == 1 else False for x in np.random.uniform(\n",
    "            0, 1, (len(data))) < 1 - test_ratio]\n",
    "        neg_mask = [not x for x in mask]\n",
    "        train_data, test_data = data[mask], data[neg_mask]\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiwoo\\AppData\\Local\\Temp\\ipykernel_19460\\3207216276.py:2: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df, num_users, num_items = read_data_ml100k()\n"
     ]
    }
   ],
   "source": [
    "TARGET_NUM, L, batch_size = 1, 5, 4096\n",
    "df, num_users, num_items = read_data_ml100k()\n",
    "train_data, test_data = split_data_ml100k(df, num_users, num_items,\n",
    "                                              'seq-aware')\n",
    "users_train, items_train, ratings_train, candidates = load_data_ml100k(\n",
    "    train_data, num_users, num_items, feedback=\"implicit\")\n",
    "users_test, items_test, ratings_test, test_candidates = load_data_ml100k(\n",
    "    test_data, num_users, num_items, feedback=\"implicit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, tensor([241., 170., 110., 255.,   4.], dtype=torch.float64), 101, 1268)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq_data = SeqDataset(users_train, items_train, L, num_users,\n",
    "                            num_items, candidates)\n",
    "train_iter = DataLoader(train_seq_data, batch_size, drop_last=True)\n",
    "test_seq_iter = train_seq_data.test_seq\n",
    "\n",
    "# user id, time step 만큼의 items, target item, neg item\n",
    "train_seq_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d\n",
    "class Caser(nn.Module):\n",
    "    def __init__(self, num_factors, num_users, num_items, L=5, d=16, # num_factors == k\n",
    "                 d_prime=4, drop_ratio=0.05, **kwargs): \n",
    "        super(Caser, self).__init__(**kwargs)\n",
    "        self.P = nn.Embedding(num_users, num_factors) # user's general taste embedding\n",
    "        self.Q = nn.Embedding(num_items, num_factors) # item embedding\n",
    "        self.d_prime, self.d = d_prime, d # vertical / horizontal filter의 갯수\n",
    "        # Vertical convolution layer\n",
    "        self.conv_v = Conv2d(in_channels=1, out_channels=d_prime, kernel_size=(L, 1))\n",
    "        # Horizontal convolution layer\n",
    "        h = [i + 1 for i in range(L)]\n",
    "        self.conv_h, self.max_pool = [], []\n",
    "        for i in h:\n",
    "            self.conv_h.append(nn.Conv2d(in_channels=1, out_channels=d, kernel_size=(i, num_factors)))\n",
    "            self.max_pool.append(nn.MaxPool1d(kernel_size=(L - i + 1)))\n",
    "        # print(self.conv_h)\n",
    "        # print('-'*100)\n",
    "        # print(self.conv_v)\n",
    "        self.conv_h, self.conv_v = nn.Sequential(*self.conv_h), nn.Sequential(self.conv_v)\n",
    "        \n",
    "        # Fully-connected layer\n",
    "        self.fc1_dim_v, self.fc1_dim_h = d_prime * num_factors, d * len(h) # output dim of vertical conv / horizontal conv\n",
    "        self.fc = nn.Linear(in_features=d_prime * num_factors + d * L, out_features=num_factors) # input : concat of vertical/horzontal conv output, output : z\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Q_prime = nn.Embedding(num_items, num_factors * 2) # another item embedding\n",
    "        self.b = nn.Embedding(num_items, 1)\n",
    "        self.dropout = nn.Dropout(drop_ratio)\n",
    "\n",
    "    def forward(self, user_id, seq, item_id):\n",
    "        item_embs = torch.unsqueeze(self.Q(seq), 1)\n",
    "        user_emb = self.P(user_id)\n",
    "        out, out_h, out_v, out_hs = None, None, None, []\n",
    "        if self.d_prime:\n",
    "            out_v = self.conv_v(item_embs)\n",
    "            out_v = out_v.reshape(out_v.shape[0], self.fc1_dim_v)\n",
    "        if self.d:\n",
    "            for conv, maxp in zip(self.conv_h, self.max_pool):\n",
    "                conv_out = torch.squeeze(self.relu(conv(item_embs)), dim=3)\n",
    "                t = maxp(conv_out)\n",
    "                pool_out = torch.squeeze(t, dim=2)\n",
    "                out_hs.append(pool_out)\n",
    "            out_h = torch.stack(out_hs, dim=1).view(batch_size,-1)\n",
    "        # print(out_v.size(), out_h.size())\n",
    "        out = torch.cat((out_v, out_h), dim=1)\n",
    "        z = self.relu(self.fc(self.dropout(out)))\n",
    "        x = torch.cat((z, user_emb), dim=1) # user_emb : user's general taste embedding\n",
    "        q_prime_i = torch.squeeze(self.Q_prime(item_id))\n",
    "        b = torch.squeeze(self.b(item_id))\n",
    "        res = (x * q_prime_i).sum(1) + b\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Caser(num_factors=10, num_users=num_users, num_items=num_items)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(BPRLoss, self).__init__(**kwargs)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, positive, negative):\n",
    "        distances = positive - negative\n",
    "        loss = - torch.sum(torch.log(self.sigmoid(distances)))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, wd, optimizer = 0.01, 10, 1e-5, 'adam'\n",
    "\n",
    "loss_func = BPRLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch 0th train iter loss: 7992.8701171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:06<01:02,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch ALL LOSS :  7141.98972486413\n",
      "1 epoch 0th train iter loss: 6453.3359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:13<00:53,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch ALL LOSS :  5930.71531080163\n",
      "2 epoch 0th train iter loss: 5393.2509765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:19<00:45,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 epoch ALL LOSS :  4893.648554262908\n",
      "3 epoch 0th train iter loss: 4621.61474609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:26<00:38,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 epoch ALL LOSS :  4023.4557468580165\n",
      "4 epoch 0th train iter loss: 3756.32421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:32<00:32,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 epoch ALL LOSS :  3291.258247707201\n",
      "5 epoch 0th train iter loss: 3117.317626953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:38<00:25,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epoch ALL LOSS :  2839.376857591712\n",
      "6 epoch 0th train iter loss: 2885.0107421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:45<00:19,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 epoch ALL LOSS :  2472.299762228261\n",
      "7 epoch 0th train iter loss: 2388.111572265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:51<00:13,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 epoch ALL LOSS :  2218.8202381963315\n",
      "8 epoch 0th train iter loss: 2265.22021484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:59<00:06,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 epoch ALL LOSS :  2056.2130180027175\n",
      "9 epoch 0th train iter loss: 2089.041748046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:06<00:00,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 epoch ALL LOSS :  1903.8975193189538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import glob\n",
    "import os\n",
    "\n",
    "train_epoch_loss = []\n",
    "val_epoch_loss_lst = []\n",
    "best_val_epoch_loss = int(1e9)\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_iter_loss = []\n",
    "    for i, values in enumerate(train_iter):\n",
    "        p_pos = model(values[0].to(device), values[1].to(device).long(), values[2].to(device)) \n",
    "        p_neg = model(values[0].to(device), values[1].to(device).long(), values[3].to(device)) \n",
    "        loss = loss_func(p_pos, p_neg)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_iter_loss.append(loss.detach().item())\n",
    "        if i%50 == 0:\n",
    "            print(f'{epoch} epoch {i}th train iter loss: {loss.detach().item()}')  \n",
    "    train_epoch_loss.append(np.mean(train_iter_loss))\n",
    "    print(f'{epoch} epoch ALL LOSS : ', np.mean(train_iter_loss))\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     model.eval()\n",
    "    #     val_epoch_loss = 0\n",
    "    #     for i, values in enumerate(test_iter):\n",
    "    #         p_pos = model(values[0].to(device), values[1].to(device), values[2].to(device)) \n",
    "    #         p_neg = model(values[0].to(device), values[1].to(device), values[3].to(device)) \n",
    "    #         loss = loss_func(p_pos, p_neg)\n",
    "    #         val_epoch_loss += loss.detach().item()\n",
    "    #     val_epoch_loss /= len(test_iter)\n",
    "    #     val_epoch_loss_lst.append(val_epoch_loss)\n",
    "\n",
    "    # if val_epoch_loss < best_val_epoch_loss:\n",
    "    #     best_val_epoch_loss = val_epoch_loss\n",
    "    #     print(f'New best model loss: {best_val_epoch_loss}')\n",
    "    #     if not os.path.exists('ncf_model'):\n",
    "    #         os.mkdir('ncf_model')\n",
    "\n",
    "    #     if os.path.exists('ncf_model/best.pth'):\n",
    "    #         os.remove('ncf_model/best.pth')\n",
    "    #         torch.save(model.state_dict(), 'ncf_model/best.pth')\n",
    "    #         print('best model is saved!')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x219a100f460>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_epoch_loss, label='train loss')\n",
    "\n",
    "# plt.plot(val_epoch_loss_lst, label='val loss')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93865c8914045f82f1cc4174d5a9f6658a56058b431eb3568707e1e9b23cbcf9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('bc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
