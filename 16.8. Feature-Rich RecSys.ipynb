{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJIlZmupSgzB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import hashlib\n",
        "import requests\n",
        "import zipfile, tarfile\n",
        "\n",
        "def download():\n",
        "    url, sha1_hash = ('http://d2l-data.s3-accelerate.amazonaws.com/ctr.zip',\n",
        "                        'e18327c48c8e8e5c23da714dd614e390d369843f')\n",
        "    cache_dir=os.path.join('..', 'data')\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
        "    if os.path.exists(fname):\n",
        "        sha1 = hashlib.sha1()\n",
        "        with open(fname, 'rb') as f:\n",
        "            while True:\n",
        "                data = f.read(1048576)\n",
        "                if not data:\n",
        "                    break\n",
        "                sha1.update(data)\n",
        "        if sha1.hexdigest() == sha1_hash:\n",
        "            return fname  # Hit cache\n",
        "    print(f'Downloading {fname} from {url}...')\n",
        "    r = requests.get(url, stream=True, verify=True)\n",
        "    with open(fname, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "    return fname\n",
        "\n",
        "def download_extract(folder=None):\n",
        "    fname = download()\n",
        "    base_dir = os.path.dirname(fname)\n",
        "    data_dir, ext = os.path.splitext(fname)\n",
        "    if ext == '.zip':\n",
        "        fp = zipfile.ZipFile(fname, 'r')\n",
        "    elif ext in ('.tar', '.gz'):\n",
        "        fp = tarfile.open(fname, 'r')\n",
        "    else:\n",
        "        assert False, 'Only zip/tar files can be extracted.'\n",
        "    fp.extractall(base_dir)\n",
        "    return os.path.join(base_dir, folder) if folder else data_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3RWziSBSgzF"
      },
      "outputs": [],
      "source": [
        "data_dir = download_extract()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpLj4mw_SgzG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CTRDataset(Dataset):\n",
        "    def __init__(self, data_path, feat_mapper=None, defaults=None,\n",
        "                 min_threshold=4, num_feat=34):\n",
        "        self.NUM_FEATS, self.count, self.data = num_feat, 0, {}\n",
        "        feat_cnts = defaultdict(lambda: defaultdict(int))\n",
        "        self.feat_mapper, self.defaults = feat_mapper, defaults\n",
        "        self.field_dims = np.zeros(self.NUM_FEATS, dtype=np.int64)\n",
        "        with open(data_path) as f:\n",
        "            for line in f:\n",
        "                instance = {}\n",
        "                values = line.rstrip('\\n').split('\\t')\n",
        "                if len(values) != self.NUM_FEATS + 1:\n",
        "                    continue\n",
        "                label = np.float32([0, 0])\n",
        "                label[int(values[0])] = 1\n",
        "                instance['y'] = [np.float32(values[0])]\n",
        "                for i in range(1, self.NUM_FEATS + 1):\n",
        "                    feat_cnts[i][values[i]] += 1\n",
        "                    instance.setdefault('x', []).append(values[i])\n",
        "                self.data[self.count] = instance\n",
        "                self.count = self.count + 1\n",
        "        if self.feat_mapper is None and self.defaults is None:\n",
        "            feat_mapper = {i: {feat for feat, c in cnt.items() if c >=\n",
        "                               min_threshold} for i, cnt in feat_cnts.items()}\n",
        "            self.feat_mapper = {i: {feat_v: idx for idx, feat_v in enumerate(feat_values)}\n",
        "                                for i, feat_values in feat_mapper.items()}\n",
        "            self.defaults = {i: len(feat_values) for i, feat_values in feat_mapper.items()}\n",
        "        for i, fm in self.feat_mapper.items():\n",
        "            self.field_dims[i - 1] = len(fm) + 1\n",
        "        self.offsets = np.array((0, *np.asarray(np.cumsum(self.field_dims))\n",
        "                                 [:-1]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.count\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feat = np.array([self.feat_mapper[i + 1].get(v, self.defaults[i + 1])\n",
        "                         for i, v in enumerate(self.data[idx]['x'])])\n",
        "        return feat + self.offsets, self.data[idx]['y']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLoAZjqfSgzH",
        "outputId": "7380f168-f11e-4959-9e45-7ea11ceec36b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 143,  145,  227,  259,  957, 1250, 1471, 1566, 1624, 1881, 2008,\n",
              "        2061, 2071, 2304, 2305, 2360, 2745, 2746, 2747, 2748, 2892, 2988,\n",
              "        3165, 3176, 3194, 3195, 3599, 3659, 3687, 3695, 3713, 3738, 3774,\n",
              "        3811]), [1.0])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data = CTRDataset(os.path.join(data_dir, 'train.csv'))\n",
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVviz4VmSgzJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "16.4autorec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
