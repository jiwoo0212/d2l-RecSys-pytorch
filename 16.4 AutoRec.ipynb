{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tf6P3PxUx69g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import zipfile\n",
        "from urllib import request\n",
        "\n",
        "def download_ml100k():\n",
        "    # download\n",
        "    url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "    savename = \"ml-100k.zip\"\n",
        "    request.urlretrieve(url, savename)\n",
        "    print('Complete!')\n",
        "    # unzip\n",
        "    file_name = os.path.join('./', savename)\n",
        "    file_zip = zipfile.ZipFile(file_name)\n",
        "    file_zip.extractall('./')\n",
        "    file_zip.close()\n",
        "\n",
        "def read_data_ml100k():\n",
        "    if not os.path.isfile(os.path.join('./ml-100k/', 'u.data')):\n",
        "        print('Download ...')\n",
        "        download_ml100k()\n",
        "    names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "    data = pd.read_csv(os.path.join('./ml-100k/', 'u.data'), '\\t', names=names,\n",
        "                       engine='python')\n",
        "    num_users = data.user_id.unique().shape[0]\n",
        "    num_items = data.item_id.unique().shape[0]\n",
        "    return data, num_users, num_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x4Mx_4d6x69i"
      },
      "outputs": [],
      "source": [
        "def load_data_ml100k(data, num_users, num_items, feedback='explicit'):\n",
        "    users, items, scores = [], [], []\n",
        "    inter = np.zeros((num_items, num_users)) if feedback == 'explicit' else {}\n",
        "    for line in data.itertuples():\n",
        "        user_index, item_index = int(line[1] - 1), int(line[2] - 1)\n",
        "        score = int(line[3]) if feedback == 'explicit' else 1\n",
        "        users.append(user_index)\n",
        "        items.append(item_index)\n",
        "        scores.append(score)\n",
        "        if feedback == 'implicit':\n",
        "            inter.setdefault(user_index, []).append(item_index)\n",
        "        else:\n",
        "            inter[item_index, user_index] = score\n",
        "    return users, items, scores, inter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zzE0ypLax69i"
      },
      "outputs": [],
      "source": [
        "def split_data_ml100k(data, num_users, num_items,\n",
        "                      split_mode='random', test_ratio=0.1):\n",
        "    \"\"\"Split the dataset in random mode or seq-aware mode.\"\"\"\n",
        "    if split_mode == 'seq-aware':\n",
        "        train_items, test_items, train_list = {}, {}, []\n",
        "        for line in data.itertuples():\n",
        "            u, i, rating, time = line[1], line[2], line[3], line[4]\n",
        "            train_items.setdefault(u, []).append((u, i, rating, time))\n",
        "            if u not in test_items or test_items[u][-1] < time:\n",
        "                test_items[u] = (i, rating, time)\n",
        "        for u in range(1, num_users + 1):\n",
        "            train_list.extend(sorted(train_items[u], key=lambda k: k[3]))\n",
        "        test_data = [(key, *value) for key, value in test_items.items()]\n",
        "        train_data = [item for item in train_list if item not in test_data]\n",
        "        train_data = pd.DataFrame(train_data)\n",
        "        test_data = pd.DataFrame(test_data)\n",
        "    else:\n",
        "        mask = [True if x == 1 else False for x in np.random.uniform(\n",
        "            0, 1, (len(data))) < 1 - test_ratio]\n",
        "        neg_mask = [not x for x in mask]\n",
        "        train_data, test_data = data[mask], data[neg_mask]\n",
        "    return train_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b2x3DeeQx69j"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "class AutoRec(nn.Module):\n",
        "    def __init__(self, num_hidden, num_users, dropout=0.05):\n",
        "        super(AutoRec, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(num_users, num_hidden, bias = True),\n",
        "            nn.Sigmoid(),\n",
        "            # nn.ReLU(True),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(num_hidden, num_users, bias=True),\n",
        "            # nn.ReLU(True),\n",
        "        )\n",
        "        self.type = type\n",
        "\n",
        "    def forward(self, input, type='train'):\n",
        "        x = self.encoder(input)\n",
        "        pred = self.decoder(x)\n",
        "        if type == 'train':  # Mask the gradient during training\n",
        "            return pred * torch.sign(input)\n",
        "        else:\n",
        "            return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJgjNNJRx69j",
        "outputId": "489b1acc-f958-4168-b433-8e638dfd3ad4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3c/k281jc6s6yq4s3qndkn6tw880000gn/T/ipykernel_13414/114522661.py:1: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
            "  data, num_users, num_items = read_data_ml100k()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of users: 943, number of items: 1682\n",
            "matrix sparsity: 0.936953\n",
            "   user_id  item_id  rating  timestamp\n",
            "0      196      242       3  881250949\n",
            "1      186      302       3  891717742\n",
            "2       22      377       1  878887116\n",
            "3      244       51       2  880606923\n",
            "4      166      346       1  886397596\n"
          ]
        }
      ],
      "source": [
        "data, num_users, num_items = read_data_ml100k()\n",
        "sparsity = 1 - len(data) / (num_users * num_items)\n",
        "print(f'number of users: {num_users}, number of items: {num_items}')\n",
        "print(f'matrix sparsity: {sparsity:f}')\n",
        "print(data.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afLJbyi_x69k",
        "outputId": "b053d406-3f46-462e-dcbf-c9dbe8d2d8aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3c/k281jc6s6yq4s3qndkn6tw880000gn/T/ipykernel_13414/2068559020.py:6: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
            "  df, num_users, num_items = read_data_ml100k()\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Load the MovieLens 100K dataset\n",
        "df, num_users, num_items = read_data_ml100k()\n",
        "train_data, test_data = split_data_ml100k(df, num_users, num_items)\n",
        "_, _, _, train_inter_mat = load_data_ml100k(train_data, num_users,\n",
        "                                                num_items)\n",
        "_, _, _, test_inter_mat = load_data_ml100k(test_data, num_users,\n",
        "                                               num_items)\n",
        "train_iter = DataLoader(train_inter_mat, shuffle=True, batch_size=256)\n",
        "test_iter = DataLoader(test_inter_mat, shuffle=True,batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0UYhMfUx69k",
        "outputId": "f752b456-3192-46d7-c3bd-9decc35f08e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([256, 943])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(train_iter)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RMSELoss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        criterion = nn.MSELoss()\n",
        "        eps = 1e-6\n",
        "        loss = torch.sqrt(criterion(x, y) + eps)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0FmshuxLx69k"
      },
      "outputs": [],
      "source": [
        "# Model initialization, training, and evaluation\n",
        "\n",
        "# param \n",
        "lr, num_epoch, weight_decay, num_hidden = 0.002, 100, 1e-5, 500\n",
        "\n",
        "net = AutoRec(num_hidden, num_users).to(device)\n",
        "loss_func = RMSELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr = lr, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7Tn50a6ux69l"
      },
      "outputs": [],
      "source": [
        "def evaluator(net, iter_matrix, device):\n",
        "    loss = 0\n",
        "    for i, values in enumerate(test_iter):\n",
        "        x = values.to(device).float()\n",
        "        output = net(x) #, type='test')\n",
        "        loss += loss_func(output,x).cpu().detach().numpy()\n",
        "    return loss/(i+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7jbfPPBx69l",
        "outputId": "9a6e1b65-ff00-485a-8d18-d13a548adff7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 1/100 [00:00<00:14,  6.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 epoch 0th train iter loss: 0.8969365954399109\n",
            "0 epoch ALL LOSS :  0.5129873667444501\n",
            "New best model loss: 0.3558124005794525\n",
            "best model is saved!\n",
            "1 epoch 0th train iter loss: 0.34472066164016724\n",
            "1 epoch ALL LOSS :  0.29806739943368094\n",
            "New best model loss: 0.27133673429489136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 4/100 [00:00<00:09, 10.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best model is saved!\n",
            "2 epoch 0th train iter loss: 0.26166975498199463\n",
            "2 epoch ALL LOSS :  0.2562912404537201\n",
            "New best model loss: 0.23301096260547638\n",
            "best model is saved!\n",
            "3 epoch 0th train iter loss: 0.26320457458496094\n",
            "3 epoch ALL LOSS :  0.23709752517087118\n",
            "New best model loss: 0.2172502875328064\n",
            "best model is saved!\n",
            "4 epoch 0th train iter loss: 0.22890062630176544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 6/100 [00:00<00:10,  9.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4 epoch ALL LOSS :  0.22891980409622192\n",
            "5 epoch 0th train iter loss: 0.20545168220996857\n",
            "5 epoch ALL LOSS :  0.2207693180867604\n",
            "New best model loss: 0.2072741836309433\n",
            "best model is saved!\n",
            "6 epoch 0th train iter loss: 0.21430175006389618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 7/100 [00:00<00:11,  8.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 epoch ALL LOSS :  0.21802244867597306\n",
            "7 epoch 0th train iter loss: 0.2087981104850769\n",
            "7 epoch ALL LOSS :  0.211034717304366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 9/100 [00:01<00:12,  7.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model loss: 0.19355420768260956\n",
            "best model is saved!\n",
            "8 epoch 0th train iter loss: 0.20635047554969788\n",
            "8 epoch ALL LOSS :  0.20758885145187378\n",
            "9 epoch 0th train iter loss: 0.19800345599651337\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 10/100 [00:01<00:13,  6.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9 epoch ALL LOSS :  0.2048286178282329\n",
            "10 epoch 0th train iter loss: 0.20334993302822113\n",
            "10 epoch ALL LOSS :  0.2021242699452809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 12/100 [00:01<00:14,  6.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11 epoch 0th train iter loss: 0.19295258820056915\n",
            "11 epoch ALL LOSS :  0.19811612367630005\n",
            "12 epoch 0th train iter loss: 0.1836269348859787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 13/100 [00:01<00:14,  5.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12 epoch ALL LOSS :  0.1940490518297468\n",
            "13 epoch 0th train iter loss: 0.20833969116210938\n",
            "13 epoch ALL LOSS :  0.1887647019965308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 14/100 [00:02<00:14,  5.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model loss: 0.16768565773963928\n",
            "best model is saved!\n",
            "14 epoch 0th train iter loss: 0.18208801746368408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 15/100 [00:02<00:16,  5.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14 epoch ALL LOSS :  0.18638863946710313\n",
            "15 epoch 0th train iter loss: 0.18982258439064026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 16/100 [00:02<00:19,  4.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15 epoch ALL LOSS :  0.18240149106298173\n",
            "16 epoch 0th train iter loss: 0.17116984724998474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 18/100 [00:02<00:15,  5.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16 epoch ALL LOSS :  0.1778790546315057\n",
            "New best model loss: 0.16631951928138733\n",
            "best model is saved!\n",
            "17 epoch 0th train iter loss: 0.16337835788726807\n",
            "17 epoch ALL LOSS :  0.17279542769704545\n",
            "New best model loss: 0.14901015162467957\n",
            "best model is saved!\n",
            "18 epoch 0th train iter loss: 0.1558874398469925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 21/100 [00:03<00:10,  7.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18 epoch ALL LOSS :  0.1706548205443791\n",
            "19 epoch 0th train iter loss: 0.14352042973041534\n",
            "19 epoch ALL LOSS :  0.1652578583785466\n",
            "20 epoch 0th train iter loss: 0.16017502546310425\n",
            "20 epoch ALL LOSS :  0.16154239433152334\n",
            "21 epoch 0th train iter loss: 0.1650228202342987\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 23/100 [00:03<00:09,  8.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21 epoch ALL LOSS :  0.15600893327168056\n",
            "New best model loss: 0.13790325820446014\n",
            "best model is saved!\n",
            "22 epoch 0th train iter loss: 0.1644732803106308\n",
            "22 epoch ALL LOSS :  0.15166705208165304\n",
            "23 epoch 0th train iter loss: 0.1523997038602829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 26/100 [00:03<00:07,  9.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23 epoch ALL LOSS :  0.147623815706798\n",
            "24 epoch 0th train iter loss: 0.14070284366607666\n",
            "24 epoch ALL LOSS :  0.1433516889810562\n",
            "25 epoch 0th train iter loss: 0.13464005291461945\n",
            "25 epoch ALL LOSS :  0.13769396713801793\n",
            "New best model loss: 0.13419100642204285\n",
            "best model is saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 28/100 [00:03<00:06, 10.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26 epoch 0th train iter loss: 0.13249792158603668\n",
            "26 epoch ALL LOSS :  0.13300725179059164\n",
            "New best model loss: 0.12771792709827423\n",
            "best model is saved!\n",
            "27 epoch 0th train iter loss: 0.13243034482002258\n",
            "27 epoch ALL LOSS :  0.12838837504386902\n",
            "28 epoch 0th train iter loss: 0.12285080552101135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 30/100 [00:03<00:06, 11.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28 epoch ALL LOSS :  0.12232542250837598\n",
            "New best model loss: 0.11331082135438919\n",
            "best model is saved!\n",
            "29 epoch 0th train iter loss: 0.11803295463323593\n",
            "29 epoch ALL LOSS :  0.11703900141375405\n",
            "New best model loss: 0.10383683443069458\n",
            "best model is saved!\n",
            "30 epoch 0th train iter loss: 0.1096210703253746\n",
            "30 epoch ALL LOSS :  0.1120166831782886\n",
            "New best model loss: 0.09672977775335312\n",
            "best model is saved!\n",
            "31 epoch 0th train iter loss: 0.10513754189014435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [00:04<00:05, 11.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31 epoch ALL LOSS :  0.10936193913221359\n",
            "32 epoch 0th train iter loss: 0.1036030501127243\n",
            "32 epoch ALL LOSS :  0.10345276658024107\n",
            "New best model loss: 0.09564714133739471\n",
            "best model is saved!\n",
            "33 epoch 0th train iter loss: 0.09731576591730118\n",
            "33 epoch ALL LOSS :  0.09980420023202896\n",
            "34 epoch 0th train iter loss: 0.0914340540766716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 36/100 [00:04<00:05, 11.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34 epoch ALL LOSS :  0.09466949105262756\n",
            "New best model loss: 0.09112022072076797\n",
            "best model is saved!\n",
            "35 epoch 0th train iter loss: 0.08175982534885406\n",
            "35 epoch ALL LOSS :  0.09025619179010391\n",
            "New best model loss: 0.08589860796928406\n",
            "best model is saved!\n",
            "36 epoch 0th train iter loss: 0.08367512375116348\n",
            "36 epoch ALL LOSS :  0.08582493024212974\n",
            "New best model loss: 0.07947792857885361\n",
            "best model is saved!\n",
            "37 epoch 0th train iter loss: 0.08391635864973068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 40/100 [00:04<00:04, 12.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37 epoch ALL LOSS :  0.08202964812517166\n",
            "38 epoch 0th train iter loss: 0.07745590806007385\n",
            "38 epoch ALL LOSS :  0.07768727838993073\n",
            "New best model loss: 0.07511525601148605\n",
            "best model is saved!\n",
            "39 epoch 0th train iter loss: 0.07382095605134964\n",
            "39 epoch ALL LOSS :  0.07432295169149127\n",
            "New best model loss: 0.07214220613241196\n",
            "best model is saved!\n",
            "40 epoch 0th train iter loss: 0.07196151465177536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 42/100 [00:04<00:04, 12.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40 epoch ALL LOSS :  0.07122843712568283\n",
            "New best model loss: 0.07097278535366058\n",
            "best model is saved!\n",
            "41 epoch 0th train iter loss: 0.0698809027671814\n",
            "41 epoch ALL LOSS :  0.06782998463937215\n",
            "New best model loss: 0.0657021701335907\n",
            "best model is saved!\n",
            "42 epoch 0th train iter loss: 0.06461498141288757\n",
            "42 epoch ALL LOSS :  0.0649032975946154\n",
            "43 epoch 0th train iter loss: 0.06432174146175385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 46/100 [00:05<00:04, 12.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43 epoch ALL LOSS :  0.06154746934771538\n",
            "New best model loss: 0.056620337069034576\n",
            "best model is saved!\n",
            "44 epoch 0th train iter loss: 0.06389894336462021\n",
            "44 epoch ALL LOSS :  0.058379976877144406\n",
            "New best model loss: 0.05505219101905823\n",
            "best model is saved!\n",
            "45 epoch 0th train iter loss: 0.05597113445401192\n",
            "45 epoch ALL LOSS :  0.05494227260351181\n",
            "New best model loss: 0.045319389551877975\n",
            "best model is saved!\n",
            "46 epoch 0th train iter loss: 0.05047023668885231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 48/100 [00:05<00:04, 12.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46 epoch ALL LOSS :  0.05270294898322651\n",
            "47 epoch 0th train iter loss: 0.05350682884454727\n",
            "47 epoch ALL LOSS :  0.050557687878608704\n",
            "New best model loss: 0.04400411620736122\n",
            "best model is saved!\n",
            "48 epoch 0th train iter loss: 0.046126361936330795\n",
            "48 epoch ALL LOSS :  0.04861649711217199\n",
            "New best model loss: 0.043983977288007736\n",
            "best model is saved!\n",
            "49 epoch 0th train iter loss: 0.0447053536772728\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 52/100 [00:05<00:03, 13.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49 epoch ALL LOSS :  0.04753859447581427\n",
            "50 epoch 0th train iter loss: 0.04327255114912987\n",
            "50 epoch ALL LOSS :  0.046368462166615894\n",
            "51 epoch 0th train iter loss: 0.04458790645003319\n",
            "51 epoch ALL LOSS :  0.04490304897938456\n",
            "New best model loss: 0.04025471583008766\n",
            "best model is saved!\n",
            "52 epoch 0th train iter loss: 0.039974283427000046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 54/100 [00:05<00:03, 13.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "52 epoch ALL LOSS :  0.04176319071224758\n",
            "New best model loss: 0.03663826733827591\n",
            "best model is saved!\n",
            "53 epoch 0th train iter loss: 0.03820708766579628\n",
            "53 epoch ALL LOSS :  0.039761982858181\n",
            "New best model loss: 0.03526958450675011\n",
            "best model is saved!\n",
            "54 epoch 0th train iter loss: 0.042658958584070206\n",
            "54 epoch ALL LOSS :  0.03844106676323073\n",
            "New best model loss: 0.034087926149368286\n",
            "best model is saved!\n",
            "55 epoch 0th train iter loss: 0.03380165249109268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 58/100 [00:06<00:03, 13.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55 epoch ALL LOSS :  0.03662122094205448\n",
            "New best model loss: 0.03173269331455231\n",
            "best model is saved!\n",
            "56 epoch 0th train iter loss: 0.038229599595069885\n",
            "56 epoch ALL LOSS :  0.036045423575810025\n",
            "57 epoch 0th train iter loss: 0.03605867177248001\n",
            "57 epoch ALL LOSS :  0.03484021446534565\n",
            "New best model loss: 0.029279490932822227\n",
            "best model is saved!\n",
            "58 epoch 0th train iter loss: 0.033712491393089294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 60/100 [00:06<00:03, 13.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "58 epoch ALL LOSS :  0.03393088494028364\n",
            "59 epoch 0th train iter loss: 0.036553237587213516\n",
            "59 epoch ALL LOSS :  0.033512116010699956\n",
            "New best model loss: 0.025115104392170906\n",
            "best model is saved!\n",
            "60 epoch 0th train iter loss: 0.03267902880907059\n",
            "60 epoch ALL LOSS :  0.03314358075814588\n",
            "61 epoch 0th train iter loss: 0.03226500004529953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 64/100 [00:06<00:02, 12.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "61 epoch ALL LOSS :  0.031243246846965382\n",
            "62 epoch 0th train iter loss: 0.03059975989162922\n",
            "62 epoch ALL LOSS :  0.03144386889679091\n",
            "63 epoch 0th train iter loss: 0.03027847409248352\n",
            "63 epoch ALL LOSS :  0.031138640163200244\n",
            "64 epoch 0th train iter loss: 0.031493596732616425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 66/100 [00:06<00:02, 12.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64 epoch ALL LOSS :  0.030270218583089963\n",
            "New best model loss: 0.02430788055062294\n",
            "best model is saved!\n",
            "65 epoch 0th train iter loss: 0.03163226693868637\n",
            "65 epoch ALL LOSS :  0.030461741345269338\n",
            "66 epoch 0th train iter loss: 0.028887426480650902\n",
            "66 epoch ALL LOSS :  0.030267077098999704\n",
            "67 epoch 0th train iter loss: 0.027141248807311058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 70/100 [00:07<00:02, 13.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67 epoch ALL LOSS :  0.02987466592873846\n",
            "New best model loss: 0.023769104853272438\n",
            "best model is saved!\n",
            "68 epoch 0th train iter loss: 0.028498586267232895\n",
            "68 epoch ALL LOSS :  0.029924928609813963\n",
            "69 epoch 0th train iter loss: 0.028206510469317436\n",
            "69 epoch ALL LOSS :  0.029056019548858916\n",
            "70 epoch 0th train iter loss: 0.02869603782892227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 72/100 [00:07<00:02, 13.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70 epoch ALL LOSS :  0.029513032042554448\n",
            "71 epoch 0th train iter loss: 0.029760554432868958\n",
            "71 epoch ALL LOSS :  0.029243174408163344\n",
            "72 epoch 0th train iter loss: 0.03092600591480732\n",
            "72 epoch ALL LOSS :  0.029438842620168413\n",
            "New best model loss: 0.023705927655100822\n",
            "best model is saved!\n",
            "73 epoch 0th train iter loss: 0.029537001624703407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 76/100 [00:07<00:01, 12.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "73 epoch ALL LOSS :  0.028659697622060776\n",
            "74 epoch 0th train iter loss: 0.026565324515104294\n",
            "74 epoch ALL LOSS :  0.028176048504454747\n",
            "75 epoch 0th train iter loss: 0.02579624392092228\n",
            "75 epoch ALL LOSS :  0.029431444459727833\n",
            "76 epoch 0th train iter loss: 0.031152505427598953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 78/100 [00:07<00:01, 12.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "76 epoch ALL LOSS :  0.029292579740285873\n",
            "77 epoch 0th train iter loss: 0.027715543285012245\n",
            "77 epoch ALL LOSS :  0.026103064151746885\n",
            "New best model loss: 0.02210150845348835\n",
            "best model is saved!\n",
            "78 epoch 0th train iter loss: 0.02554502710700035\n",
            "78 epoch ALL LOSS :  0.024965370073914528\n",
            "79 epoch 0th train iter loss: 0.022429801523685455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 82/100 [00:08<00:01, 12.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79 epoch ALL LOSS :  0.02421415357717446\n",
            "New best model loss: 0.021834854036569595\n",
            "best model is saved!\n",
            "80 epoch 0th train iter loss: 0.025780104100704193\n",
            "80 epoch ALL LOSS :  0.023285956255027225\n",
            "New best model loss: 0.02002205140888691\n",
            "best model is saved!\n",
            "81 epoch 0th train iter loss: 0.022831521928310394\n",
            "81 epoch ALL LOSS :  0.023126287119729177\n",
            "82 epoch 0th train iter loss: 0.02043713442981243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 84/100 [00:08<00:01, 12.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "82 epoch ALL LOSS :  0.022667855290429934\n",
            "New best model loss: 0.019659429788589478\n",
            "best model is saved!\n",
            "83 epoch 0th train iter loss: 0.0205918587744236\n",
            "83 epoch ALL LOSS :  0.022900122350880077\n",
            "84 epoch 0th train iter loss: 0.022287793457508087\n",
            "84 epoch ALL LOSS :  0.022306415917617933\n",
            "New best model loss: 0.018156709149479866\n",
            "best model is saved!\n",
            "85 epoch 0th train iter loss: 0.021658528596162796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 88/100 [00:08<00:00, 12.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "85 epoch ALL LOSS :  0.02194949665239879\n",
            "New best model loss: 0.017107967287302017\n",
            "best model is saved!\n",
            "86 epoch 0th train iter loss: 0.021085530519485474\n",
            "86 epoch ALL LOSS :  0.021558962230171477\n",
            "87 epoch 0th train iter loss: 0.02068519964814186\n",
            "87 epoch ALL LOSS :  0.021676100524408475\n",
            "88 epoch 0th train iter loss: 0.021535657346248627\n",
            "88 epoch ALL LOSS :  0.020272142120770047\n",
            "89 epoch 0th train iter loss: 0.02149266004562378\n",
            "89 epoch ALL LOSS :  0.020334882927792414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 90/100 [00:08<00:00, 11.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model loss: 0.015865519642829895\n",
            "best model is saved!\n",
            "90 epoch 0th train iter loss: 0.01946530118584633\n",
            "90 epoch ALL LOSS :  0.02132737822830677\n",
            "91 epoch 0th train iter loss: 0.019811294972896576\n",
            "91 epoch ALL LOSS :  0.020682383062584058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 94/100 [00:09<00:00, 10.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "92 epoch 0th train iter loss: 0.02016935870051384\n",
            "92 epoch ALL LOSS :  0.02123210339673928\n",
            "93 epoch 0th train iter loss: 0.021395700052380562\n",
            "93 epoch ALL LOSS :  0.02106680827481406\n",
            "94 epoch 0th train iter loss: 0.020658712834119797\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 96/100 [00:09<00:00, 10.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "94 epoch ALL LOSS :  0.020129079531346048\n",
            "95 epoch 0th train iter loss: 0.018606282770633698\n",
            "95 epoch ALL LOSS :  0.020231455298406736\n",
            "96 epoch 0th train iter loss: 0.019580155611038208\n",
            "96 epoch ALL LOSS :  0.02062005123921803\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 98/100 [00:09<00:00, 10.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97 epoch 0th train iter loss: 0.02257140539586544\n",
            "97 epoch ALL LOSS :  0.02101099943476064\n",
            "98 epoch 0th train iter loss: 0.02138257399201393\n",
            "98 epoch ALL LOSS :  0.020512683583157405\n",
            "99 epoch 0th train iter loss: 0.020768603309988976\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:09<00:00, 10.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99 epoch ALL LOSS :  0.02092785281794412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_epoch_loss = []\n",
        "val_epoch_loss_lst = []\n",
        "best_val_epoch_loss = int(1e9)\n",
        "for epoch in tqdm(range(num_epoch)):\n",
        "    train_iter_loss = []\n",
        "    for i, x in enumerate(train_iter):\n",
        "        x = x.to(device).float()\n",
        "        # ===================forward=====================\n",
        "        preds = net(x)\n",
        "        loss = loss_func(preds, x)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_iter_loss.append(loss.detach().item())\n",
        "        if i%50 == 0:\n",
        "            print(f'{epoch} epoch {i}th train iter loss: {loss.detach().item()}')  \n",
        "    train_epoch_loss.append(np.mean(train_iter_loss))\n",
        "    print(f'{epoch} epoch ALL LOSS : ', np.mean(train_iter_loss))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        net.eval()\n",
        "        val_epoch_loss = 0\n",
        "        for i, values in enumerate(test_iter):\n",
        "            x = x.to(device).float()\n",
        "            preds = net(x)\n",
        "            loss = loss_func(preds, x)\n",
        "            val_epoch_loss += loss.detach().item()\n",
        "    val_epoch_loss /= len(test_iter)\n",
        "    val_epoch_loss_lst.append(val_epoch_loss)\n",
        "\n",
        "    if val_epoch_loss < best_val_epoch_loss:\n",
        "        best_val_epoch_loss = val_epoch_loss\n",
        "        print(f'New best model loss: {best_val_epoch_loss}')\n",
        "        if not os.path.exists('model'):\n",
        "            os.mkdir('model')\n",
        "\n",
        "        if os.path.exists('model/best.pth'):\n",
        "            os.remove('model/best.pth')\n",
        "        torch.save(net.state_dict(), 'model/best.pth')\n",
        "        print('best model is saved!')\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "oD7EJvgNx69m",
        "outputId": "34f38f74-8ddf-4d6a-f259-acbb30aca449"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x14c39cc70>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(val_epoch_loss_lst, label='train loss')\n",
        "\n",
        "plt.plot(train_epoch_loss, label='val loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "autorec_pytorch.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
