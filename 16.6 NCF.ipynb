{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import zipfile\n",
    "from urllib import request\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, num_factors, num_users, num_items, nums_hiddens,\n",
    "                **kwargs):\n",
    "        super(NeuMF, self).__init__(**kwargs)\n",
    "        self.P = nn.Embedding(num_users, num_factors) # GMF의 user\n",
    "        self.Q = nn.Embedding(num_items, num_factors) # GMF의 item\n",
    "        self.U = nn.Embedding(num_users, num_factors) # MLP의 user\n",
    "        self.V = nn.Embedding(num_items, num_factors) # MLP의 item\n",
    "        layers = []\n",
    "        before_layer = num_factors*2\n",
    "        for num_hiddens in nums_hiddens: \n",
    "            layers.append(nn.Linear(before_layer, num_hiddens, bias=True))\n",
    "            layers.append(nn.ReLU())\n",
    "            before_layer = num_hiddens\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.prediction_layer = nn.Linear(before_layer*2, 1, bias=False)\n",
    "\n",
    "    def forward(self, user_id, item_id):\n",
    "        p_mf = self.P(user_id)\n",
    "        q_mf = self.Q(item_id)\n",
    "        gmf = p_mf * q_mf\n",
    "        p_mlp = self.U(user_id)\n",
    "        q_mlp = self.V(item_id) # [2, 1, 10] (batch, 1, 10) 사이즈\n",
    "        mlp = self.mlp(torch.cat((torch.squeeze(p_mlp, 1) , torch.squeeze(p_mlp, 1)), dim=1)) # (batch size, 20) -> (batch_size, 10)\n",
    "        con_res = torch.cat((torch.squeeze(gmf), mlp), dim=1)\n",
    "        pred = self.prediction_layer(con_res)\n",
    "        return nn.Sigmoid()(pred) # sigmoid node는 1, 0~1사이의 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRDataset(Dataset):\n",
    "    \"\"\"\n",
    "    user id, 구매한 item id, 구매하지않은 item id\n",
    "    \"\"\"\n",
    "    def __init__(self, users, items, candidates, num_items):\n",
    "        self.users = users\n",
    "        self.items = items\n",
    "        self.cand = candidates\n",
    "        self.all = set([i for i in range(num_items)]) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 해당 인덱스의 고객이 구매한 아이템을 제외한 전체 아이템\n",
    "        neg_items = list(self.all - set(self.cand[int(self.users[idx])]))\n",
    "        indices = random.randint(0, len(neg_items) - 1)\n",
    "        return self.users[idx], self.items[idx], neg_items[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ml100k():\n",
    "    # download\n",
    "    url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "    savename = \"ml-100k.zip\"\n",
    "    request.urlretrieve(url, savename)\n",
    "    print('Complete!')\n",
    "    # unzip\n",
    "    file_name = os.path.join('./', savename)\n",
    "    file_zip = zipfile.ZipFile(file_name)\n",
    "    file_zip.extractall('./')\n",
    "    file_zip.close()\n",
    "\n",
    "def read_data_ml100k():\n",
    "    \"\"\"\n",
    "    데이터를 다운받고, dataframe형태의 data, user id목록, itme id 목록 반환\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(os.path.join('./ml-100k/', 'u.data')):\n",
    "        print('Download ...')\n",
    "        download_ml100k()\n",
    "    names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(os.path.join('./ml-100k/', 'u.data'), '\\t', names=names,\n",
    "                       engine='python')\n",
    "    num_users = data.user_id.unique().shape[0]\n",
    "    num_items = data.item_id.unique().shape[0]\n",
    "    return data, num_users, num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_ml100k(data, num_users, num_items, feedback='explicit'):\n",
    "    \"\"\"\n",
    "    과정은 정확히 이해안되는데 user id, item id, score, 유저-아이템 행렬 반환\n",
    "    explicit 일때는 유저 아이템 행렬\n",
    "    implicit 일때는 key : 유저, val : 아이템의 리스트로 하는 dict \n",
    "    \"\"\"\n",
    "    users, items, scores = [], [], []\n",
    "    inter = np.zeros((num_items, num_users)) if feedback == 'explicit' else {}\n",
    "    for line in data.itertuples():\n",
    "        user_index, item_index = int(line[1] - 1), int(line[2] - 1)\n",
    "        score = int(line[3]) if feedback == 'explicit' else 1\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "        if feedback == 'implicit':\n",
    "            inter.setdefault(user_index, []).append(item_index)\n",
    "        else:\n",
    "            inter[item_index, user_index] = score\n",
    "    return users, items, scores, inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_ml100k(data, num_users, num_items,\n",
    "                      split_mode='random', test_ratio=0.1):\n",
    "    \"\"\"Split the dataset in random mode or seq-aware mode.\"\"\"\n",
    "    if split_mode == 'seq-aware':\n",
    "        train_items, test_items, train_list = {}, {}, []\n",
    "        for line in data.itertuples():\n",
    "            u, i, rating, time = line[1], line[2], line[3], line[4]\n",
    "            train_items.setdefault(u, []).append((u, i, rating, time))\n",
    "            if u not in test_items or test_items[u][-1] < time:\n",
    "                test_items[u] = (i, rating, time)\n",
    "        for u in range(1, num_users + 1):\n",
    "            train_list.extend(sorted(train_items[u], key=lambda k: k[3]))\n",
    "        test_data = [(key, *value) for key, value in test_items.items()]\n",
    "        train_data = [item for item in train_list if item not in test_data]\n",
    "        train_data = pd.DataFrame(train_data)\n",
    "        test_data = pd.DataFrame(test_data)\n",
    "    else:\n",
    "        mask = [True if x == 1 else False for x in np.random.uniform(\n",
    "            0, 1, (len(data))) < 1 - test_ratio]\n",
    "        neg_mask = [not x for x in mask]\n",
    "        train_data, test_data = data[mask], data[neg_mask]\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiwoo\\AppData\\Local\\Temp\\ipykernel_28920\\1216354282.py:2: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df, num_users, num_items = read_data_ml100k()\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "df, num_users, num_items = read_data_ml100k()\n",
    "train_data, test_data = split_data_ml100k(df, num_users, num_items,\n",
    "                                              'seq-aware')\n",
    "users_train, items_train, ratings_train, candidates = load_data_ml100k(\n",
    "    train_data, num_users, num_items, feedback=\"implicit\")\n",
    "users_test, items_test, ratings_test, test_candidates = load_data_ml100k(\n",
    "    test_data, num_users, num_items, feedback=\"implicit\")\n",
    "\n",
    "\n",
    "train_iter = DataLoader(\n",
    "    PRDataset(users_train, items_train, candidates, num_items), batch_size=batch_size)\n",
    "\n",
    "test_iter = DataLoader(\n",
    "    PRDataset(users_test, items_test, test_candidates, num_items), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter)) # user, pos, neg\n",
    "print(len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NeuMF(num_factors=10, num_users=num_users, num_items=num_items, nums_hiddens=[10, 10, 10])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(BPRLoss, self).__init__(**kwargs)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, positive, negative):\n",
    "        distances = positive - negative\n",
    "        print('distances', distances[0])\n",
    "        loss1 = self.sigmoid(distances)\n",
    "        print('sigmoid', loss1[0])\n",
    "        loss2 = torch.log(loss1)\n",
    "        print('log', loss2[0])\n",
    "        loss = - torch.sum(loss2) #, 0, keepdims=True)\n",
    "        print('all loss', loss)\n",
    "        # loss = - torch.sum(torch.log(self.sigmoid(distances)))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, wd, optimizer = 0.01, 10, 1e-5, 'adam'\n",
    "\n",
    "loss_func = BPRLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances tensor([0.1798], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "sigmoid tensor([0.5448], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "log tensor([-0.6073], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "all loss tensor(713.7936, device='cuda:0', grad_fn=<NegBackward0>)\n",
      "0 epoch 0th train iter loss: 713.7936401367188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import glob\n",
    "import os\n",
    "\n",
    "train_epoch_loss = []\n",
    "val_epoch_loss_lst = []\n",
    "best_val_epoch_loss = int(1e9)\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_iter_loss = []\n",
    "    for i, values in enumerate(train_iter):\n",
    "        if i==1:\n",
    "            break\n",
    "        p_pos = model(values[0].to(device), values[1].to(device)) \n",
    "        p_neg = model(values[0].to(device), values[2].to(device)) \n",
    "        loss = loss_func(p_pos, p_neg)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_iter_loss.append(loss.detach().item())\n",
    "        if i%50 == 0:\n",
    "            print(f'{epoch} epoch {i}th train iter loss: {loss.detach().item()}')  \n",
    "    break\n",
    "    train_epoch_loss.append(np.mean(train_iter_loss))\n",
    "    print(f'{epoch} epoch ALL LOSS : ', np.mean(train_iter_loss))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        for i, values in enumerate(test_iter):\n",
    "            p_pos = model(values[0].to(device), values[1].to(device)) \n",
    "            p_neg = model(values[0].to(device), values[2].to(device)) \n",
    "            loss = loss_func(p_pos, p_neg)\n",
    "            val_epoch_loss += loss.detach().item()\n",
    "        val_epoch_loss /= len(test_iter)\n",
    "        val_epoch_loss_lst.append(val_epoch_loss)\n",
    "\n",
    "    if val_epoch_loss < best_val_epoch_loss:\n",
    "        best_val_epoch_loss = val_epoch_loss\n",
    "        print(f'New best model loss: {best_val_epoch_loss}')\n",
    "        if not os.path.exists('ncf_model'):\n",
    "            os.mkdir('ncf_model')\n",
    "\n",
    "        if os.path.exists('ncf_model/best.pth'):\n",
    "            os.remove('ncf_model/best.pth')\n",
    "            torch.save(model.state_dict(), 'ncf_model/best.pth')\n",
    "            print('best model is saved!')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20e9a98d0a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(val_epoch_loss_lst, label='train loss')\n",
    "\n",
    "plt.plot(train_epoch_loss, label='val loss')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93865c8914045f82f1cc4174d5a9f6658a56058b431eb3568707e1e9b23cbcf9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('bc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
