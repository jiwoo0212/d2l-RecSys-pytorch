{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import zipfile\n",
    "from urllib import request\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, num_factors, num_users, num_items, nums_hiddens,\n",
    "                **kwargs):\n",
    "        super(NeuMF, self).__init__(**kwargs)\n",
    "        self.P = nn.Embedding(num_users, num_factors) # GMF의 user\n",
    "        self.Q = nn.Embedding(num_items, num_factors) # GMF의 item\n",
    "        self.U = nn.Embedding(num_users, num_factors) # MLP의 user\n",
    "        self.V = nn.Embedding(num_items, num_factors) # MLP의 item\n",
    "        layers = []\n",
    "        before_layer = num_factors*2\n",
    "        for num_hiddens in nums_hiddens: \n",
    "            layers.append(nn.Linear(before_layer, num_hiddens, bias=True))\n",
    "            layers.append(nn.ReLU())\n",
    "            before_layer = num_hiddens\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.prediction_layer = nn.Linear(before_layer*2, 1, bias=False)\n",
    "\n",
    "    def forward(self, user_id, item_id):\n",
    "        p_mf = self.P(user_id)\n",
    "        q_mf = self.Q(item_id)\n",
    "        gmf = p_mf * q_mf\n",
    "        p_mlp = self.U(user_id)\n",
    "        q_mlp = self.V(item_id) # [2, 1, 10] (batch, 1, 10) 사이즈\n",
    "        mlp = self.mlp(torch.cat((torch.squeeze(p_mlp, 1) , torch.squeeze(p_mlp, 1)), dim=1)) # (batch size, 20) -> (batch_size, 10)\n",
    "        con_res = torch.cat((torch.squeeze(gmf), mlp), dim=1)\n",
    "        pred = self.prediction_layer(con_res)\n",
    "        return nn.Sigmoid()(pred) # sigmoid node는 1, 0~1사이의 값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRDataset(Dataset):\n",
    "    \"\"\"\n",
    "    user id, 구매한 item id, 구매하지않은 item id\n",
    "    \"\"\"\n",
    "    def __init__(self, users, items, candidates, num_items):\n",
    "        self.users = users\n",
    "        self.items = items\n",
    "        self.cand = candidates\n",
    "        self.all = set([i for i in range(num_items)]) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 해당 인덱스의 고객이 구매한 아이템을 제외한 전체 아이템\n",
    "        neg_items = list(self.all - set(self.cand[int(self.users[idx])]))\n",
    "        indices = random.randint(0, len(neg_items) - 1)\n",
    "        return self.users[idx], self.items[idx], neg_items[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ml100k():\n",
    "    # download\n",
    "    url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "    savename = \"ml-100k.zip\"\n",
    "    request.urlretrieve(url, savename)\n",
    "    print('Complete!')\n",
    "    # unzip\n",
    "    file_name = os.path.join('./', savename)\n",
    "    file_zip = zipfile.ZipFile(file_name)\n",
    "    file_zip.extractall('./')\n",
    "    file_zip.close()\n",
    "\n",
    "def read_data_ml100k():\n",
    "    \"\"\"\n",
    "    데이터를 다운받고, dataframe형태의 data, user id목록, itme id 목록 반환\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(os.path.join('./ml-100k/', 'u.data')):\n",
    "        print('Download ...')\n",
    "        download_ml100k()\n",
    "    names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(os.path.join('./ml-100k/', 'u.data'), '\\t', names=names,\n",
    "                       engine='python')\n",
    "    num_users = data.user_id.unique().shape[0]\n",
    "    num_items = data.item_id.unique().shape[0]\n",
    "    return data, num_users, num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_ml100k(data, num_users, num_items, feedback='explicit'):\n",
    "    \"\"\"\n",
    "    과정은 정확히 이해안되는데 user id, item id, score, 유저-아이템 행렬 반환\n",
    "    explicit 일때는 유저 아이템 행렬\n",
    "    implicit 일때는 key : 유저, val : 아이템 리스트 인 dict \n",
    "    \"\"\"\n",
    "    users, items, scores = [], [], []\n",
    "    inter = np.zeros((num_items, num_users)) if feedback == 'explicit' else {}\n",
    "    for line in data.itertuples():\n",
    "        user_index, item_index = int(line[1] - 1), int(line[2] - 1)\n",
    "        score = int(line[3]) if feedback == 'explicit' else 1\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "        if feedback == 'implicit':\n",
    "            inter.setdefault(user_index, []).append(item_index)\n",
    "        else:\n",
    "            inter[item_index, user_index] = score\n",
    "    return users, items, scores, inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_ml100k(data, num_users, num_items,\n",
    "                      split_mode='random', test_ratio=0.1):\n",
    "    \"\"\"Split the dataset in random mode or seq-aware mode.\"\"\"\n",
    "    if split_mode == 'seq-aware':\n",
    "        train_items, test_items, train_list = {}, {}, []\n",
    "        for line in data.itertuples():\n",
    "            u, i, rating, time = line[1], line[2], line[3], line[4]\n",
    "            train_items.setdefault(u, []).append((u, i, rating, time))\n",
    "            if u not in test_items or test_items[u][-1] < time:\n",
    "                test_items[u] = (i, rating, time)\n",
    "        for u in range(1, num_users + 1):\n",
    "            train_list.extend(sorted(train_items[u], key=lambda k: k[3]))\n",
    "        test_data = [(key, *value) for key, value in test_items.items()]\n",
    "        train_data = [item for item in train_list if item not in test_data]\n",
    "        train_data = pd.DataFrame(train_data)\n",
    "        test_data = pd.DataFrame(test_data)\n",
    "    else:\n",
    "        mask = [True if x == 1 else False for x in np.random.uniform(\n",
    "            0, 1, (len(data))) < 1 - test_ratio]\n",
    "        neg_mask = [not x for x in mask]\n",
    "        train_data, test_data = data[mask], data[neg_mask]\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiwoo\\AppData\\Local\\Temp\\ipykernel_3476\\1216354282.py:2: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df, num_users, num_items = read_data_ml100k()\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "df, num_users, num_items = read_data_ml100k()\n",
    "train_data, test_data = split_data_ml100k(df, num_users, num_items,\n",
    "                                              'seq-aware')\n",
    "users_train, items_train, ratings_train, candidates = load_data_ml100k(\n",
    "    train_data, num_users, num_items, feedback=\"implicit\")\n",
    "users_test, items_test, ratings_test, test_candidates = load_data_ml100k(\n",
    "    test_data, num_users, num_items, feedback=\"implicit\")\n",
    "\n",
    "\n",
    "train_iter = DataLoader(\n",
    "    PRDataset(users_train, items_train, candidates, num_items), batch_size=batch_size)\n",
    "\n",
    "test_iter = DataLoader(\n",
    "    PRDataset(users_test, items_test, test_candidates, num_items), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter)) # user, pos, neg\n",
    "print(len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NeuMF(num_factors=10, num_users=num_users, num_items=num_items, nums_hiddens=[10, 10, 10])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(BPRLoss, self).__init__(**kwargs)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, positive, negative):\n",
    "        distances = positive - negative\n",
    "        loss = - torch.sum(torch.log(self.sigmoid(distances)))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, wd, optimizer = 0.01, 10, 1e-5, 'adam'\n",
    "\n",
    "loss_func = BPRLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch 0th train iter loss: 714.7183227539062\n",
      "0 epoch 50th train iter loss: 709.9032592773438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:04<00:41,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch ALL LOSS :  708.36642927976\n",
      "New best model loss: 653.52587890625\n",
      "1 epoch 0th train iter loss: 709.9814453125\n",
      "1 epoch 50th train iter loss: 709.5103759765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:09<00:37,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch ALL LOSS :  707.7299899071762\n",
      "New best model loss: 653.3294067382812\n",
      "2 epoch 0th train iter loss: 709.955078125\n",
      "2 epoch 50th train iter loss: 708.8931884765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:14<00:33,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 epoch ALL LOSS :  705.473836053278\n",
      "New best model loss: 651.0391845703125\n",
      "3 epoch 0th train iter loss: 706.0966796875\n",
      "3 epoch 50th train iter loss: 687.4312744140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:18<00:28,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 epoch ALL LOSS :  678.9842302774646\n",
      "New best model loss: 613.6728515625\n",
      "4 epoch 0th train iter loss: 667.6949462890625\n",
      "4 epoch 50th train iter loss: 626.11181640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:23<00:23,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 epoch ALL LOSS :  609.1841053127014\n",
      "New best model loss: 575.6744384765625\n",
      "5 epoch 0th train iter loss: 605.0701904296875\n",
      "5 epoch 50th train iter loss: 542.4965209960938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:27<00:18,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epoch ALL LOSS :  552.1774619190963\n",
      "New best model loss: 547.4964599609375\n",
      "6 epoch 0th train iter loss: 552.2630615234375\n",
      "6 epoch 50th train iter loss: 514.5670776367188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:32<00:13,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 epoch ALL LOSS :  521.5444250991663\n",
      "New best model loss: 530.1261596679688\n",
      "7 epoch 0th train iter loss: 515.9246826171875\n",
      "7 epoch 50th train iter loss: 494.45294189453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:36<00:09,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 epoch ALL LOSS :  501.16792722092464\n",
      "8 epoch 0th train iter loss: 489.92584228515625\n",
      "8 epoch 50th train iter loss: 486.043701171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:41<00:04,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 epoch ALL LOSS :  488.73514895095036\n",
      "New best model loss: 521.4351806640625\n",
      "9 epoch 0th train iter loss: 480.5716857910156\n",
      "9 epoch 50th train iter loss: 493.1099853515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:45<00:00,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 epoch ALL LOSS :  479.0600633129631\n",
      "New best model loss: 518.424560546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import glob\n",
    "import os\n",
    "\n",
    "train_epoch_loss = []\n",
    "val_epoch_loss_lst = []\n",
    "best_val_epoch_loss = int(1e9)\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_iter_loss = []\n",
    "    for i, values in enumerate(train_iter):\n",
    "        p_pos = model(values[0].to(device), values[1].to(device)) \n",
    "        p_neg = model(values[0].to(device), values[2].to(device)) \n",
    "        loss = loss_func(p_pos, p_neg)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_iter_loss.append(loss.detach().item())\n",
    "        if i%50 == 0:\n",
    "            print(f'{epoch} epoch {i}th train iter loss: {loss.detach().item()}')  \n",
    "    train_epoch_loss.append(np.mean(train_iter_loss))\n",
    "    print(f'{epoch} epoch ALL LOSS : ', np.mean(train_iter_loss))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        for i, values in enumerate(test_iter):\n",
    "            p_pos = model(values[0].to(device), values[1].to(device)) \n",
    "            p_neg = model(values[0].to(device), values[2].to(device)) \n",
    "            loss = loss_func(p_pos, p_neg)\n",
    "            val_epoch_loss += loss.detach().item()\n",
    "        val_epoch_loss /= len(test_iter)\n",
    "        val_epoch_loss_lst.append(val_epoch_loss)\n",
    "\n",
    "    if val_epoch_loss < best_val_epoch_loss:\n",
    "        best_val_epoch_loss = val_epoch_loss\n",
    "        print(f'New best model loss: {best_val_epoch_loss}')\n",
    "        if not os.path.exists('ncf_model'):\n",
    "            os.mkdir('ncf_model')\n",
    "\n",
    "        if os.path.exists('ncf_model/best.pth'):\n",
    "            os.remove('ncf_model/best.pth')\n",
    "            torch.save(model.state_dict(), 'ncf_model/best.pth')\n",
    "            print('best model is saved!')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29a872afaf0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(val_epoch_loss_lst, label='train loss')\n",
    "\n",
    "plt.plot(train_epoch_loss, label='val loss')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93865c8914045f82f1cc4174d5a9f6658a56058b431eb3568707e1e9b23cbcf9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('bc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
