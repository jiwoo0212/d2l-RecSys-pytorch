{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import zipfile\n",
    "from urllib import request\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ml100k():\n",
    "    # download\n",
    "    url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "    savename = \"ml-100k.zip\"\n",
    "    request.urlretrieve(url, savename)\n",
    "    print('Complete!')\n",
    "    # unzip\n",
    "    file_name = os.path.join('./', savename)\n",
    "    file_zip = zipfile.ZipFile(file_name)\n",
    "    file_zip.extractall('./')\n",
    "    file_zip.close()\n",
    "\n",
    "def read_data_ml100k():\n",
    "    if not os.path.isfile(os.path.join('./ml-100k/', 'u.data')):\n",
    "        print('Download ...')\n",
    "        download_ml100k()\n",
    "    names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(os.path.join('./ml-100k/', 'u.data'), '\\t', names=names,\n",
    "                       engine='python')\n",
    "    num_users = data.user_id.unique().shape[0]\n",
    "    num_items = data.item_id.unique().shape[0]\n",
    "    return data, num_users, num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_ml100k(data, num_users, num_items, feedback='explicit'):\n",
    "    users, items, scores = [], [], []\n",
    "    inter = np.zeros((num_items, num_users)) if feedback == 'explicit' else {}\n",
    "    for line in data.itertuples():\n",
    "        user_index, item_index = int(line[1] - 1), int(line[2] - 1)\n",
    "        score = int(line[3]) if feedback == 'explicit' else 1\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "        if feedback == 'implicit':\n",
    "            inter.setdefault(user_index, []).append(item_index)\n",
    "        else:\n",
    "            inter[item_index, user_index] = score\n",
    "    return users, items, scores, inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_ml100k(data, num_users, num_items,\n",
    "                      split_mode='random', test_ratio=0.1):\n",
    "    \"\"\"Split the dataset in random mode or seq-aware mode.\"\"\"\n",
    "    if split_mode == 'seq-aware':\n",
    "        train_items, test_items, train_list = {}, {}, []\n",
    "        for line in data.itertuples():\n",
    "            u, i, rating, time = line[1], line[2], line[3], line[4]\n",
    "            train_items.setdefault(u, []).append((u, i, rating, time))\n",
    "            if u not in test_items or test_items[u][-1] < time:\n",
    "                test_items[u] = (i, rating, time)\n",
    "        for u in range(1, num_users + 1):\n",
    "            train_list.extend(sorted(train_items[u], key=lambda k: k[3]))\n",
    "        test_data = [(key, *value) for key, value in test_items.items()]\n",
    "        train_data = [item for item in train_list if item not in test_data]\n",
    "        train_data = pd.DataFrame(train_data)\n",
    "        test_data = pd.DataFrame(test_data)\n",
    "    else:\n",
    "        mask = [True if x == 1 else False for x in np.random.uniform(\n",
    "            0, 1, (len(data))) < 1 - test_ratio]\n",
    "        neg_mask = [not x for x in mask]\n",
    "        train_data, test_data = data[mask], data[neg_mask]\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrayDataset(Dataset):\n",
    "\n",
    "    def __init__(self, user, item, rating, transform=None):\n",
    "        self.user = user\n",
    "        self.item = item\n",
    "        self.rating = rating\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.column_stack((self.user, self.item, self.rating))\n",
    "        if self.transform:\n",
    "            arr = self.transform(arr)\n",
    "        return torch.Tensor(arr[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    # print('fn', type(batch), len(batch), batch[0])\n",
    "    # batch는 tensor가 batch size만큼 들어간 리스트\n",
    "    batch = torch.stack(batch)\n",
    "    return batch[:, 0], batch[:, 1], batch[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_load_ml100k(split_mode='seq-aware', feedback='explicit',\n",
    "                          test_ratio=0.1, batch_size=256):\n",
    "    data, num_users, num_items = read_data_ml100k()\n",
    "    # df load\n",
    "    train_data, test_data = split_data_ml100k(\n",
    "        data, num_users, num_items, split_mode, test_ratio)\n",
    "    # user, item, rating load\n",
    "    train_u, train_i, train_r, _ = load_data_ml100k(\n",
    "        train_data, num_users, num_items, feedback)\n",
    "    test_u, test_i, test_r, _ = load_data_ml100k(\n",
    "        test_data, num_users, num_items, feedback)\n",
    "    # u,i,r을 묶어서 해당 idx 반환\n",
    "    train_set = ArrayDataset(\n",
    "        np.array(train_u), np.array(train_i), np.array(train_r))\n",
    "    test_set = ArrayDataset(\n",
    "        np.array(test_u), np.array(test_i), np.array(test_r))\n",
    "    # u, i, r를 batch 단위의 tensor로 반환\n",
    "    train_iter = DataLoader(\n",
    "        train_set, shuffle=True,\n",
    "        batch_size=batch_size, \n",
    "        collate_fn=collate_batch\n",
    "        )\n",
    "    test_iter = DataLoader(\n",
    "        test_set, batch_size=batch_size, \n",
    "        collate_fn=collate_batch\n",
    "        )\n",
    "    return num_users, num_items, train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, num_factors, num_users, num_items, **kwargs):\n",
    "        super(MF, self).__init__(**kwargs)\n",
    "        self.P = nn.Embedding(num_users, num_factors)\n",
    "        self.Q = nn.Embedding(num_items, num_factors)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "\n",
    "    def forward(self, user_id, item_id):\n",
    "        P_u = self.P(user_id)\n",
    "        Q_i = self.Q(item_id)\n",
    "        b_u = self.user_bias(user_id)\n",
    "        b_i = self.item_bias(item_id)\n",
    "        outputs = (P_u * Q_i).sum(axis=1) + np.squeeze(b_u) + np.squeeze(b_i)\n",
    "        return outputs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        criterion = nn.MSELoss()\n",
    "        eps = 1e-6\n",
    "        loss = torch.sqrt(criterion(x, y) + eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiwoo\\AppData\\Local\\Temp\\ipykernel_32564\\1723117690.py:3: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  data, num_users, num_items = read_data_ml100k()\n"
     ]
    }
   ],
   "source": [
    "num_users, num_items, train_iter, test_iter = split_and_load_ml100k(\n",
    "    test_ratio=0.1, batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MF(\n",
       "  (P): Embedding(943, 30)\n",
       "  (Q): Embedding(1682, 30)\n",
       "  (user_bias): Embedding(943, 1)\n",
       "  (item_bias): Embedding(1682, 1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MF(30, num_users, num_items)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, wd = 0.002, 50, 1e-5\n",
    "\n",
    "loss_func = RMSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch 0th train iter loss: 6.724614143371582\n",
      "0 epoch 50th train iter loss: 6.575613975524902\n",
      "0 epoch 100th train iter loss: 6.398324966430664\n",
      "0 epoch 150th train iter loss: 6.321621417999268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [01:06<54:04, 66.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch ALL LOSS :  6.4759623635675485\n",
      "New best model loss: 6.09443998336792\n",
      "best model is saved!\n",
      "1 epoch 0th train iter loss: 5.93121862411499\n",
      "1 epoch 50th train iter loss: 6.13629674911499\n",
      "1 epoch 100th train iter loss: 5.834310054779053\n",
      "1 epoch 150th train iter loss: 5.753340721130371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [02:05<49:50, 62.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch ALL LOSS :  5.778293022175425\n",
      "New best model loss: 5.631260871887207\n",
      "best model is saved!\n",
      "2 epoch 0th train iter loss: 5.2310614585876465\n",
      "2 epoch 50th train iter loss: 5.306921005249023\n",
      "2 epoch 100th train iter loss: 5.387821674346924\n",
      "2 epoch 150th train iter loss: 4.8017683029174805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [03:06<48:17, 61.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 epoch ALL LOSS :  5.144985073620511\n",
      "New best model loss: 5.201018333435059\n",
      "best model is saved!\n",
      "3 epoch 0th train iter loss: 4.804595947265625\n",
      "3 epoch 50th train iter loss: 4.7749505043029785\n",
      "3 epoch 100th train iter loss: 4.501147747039795\n",
      "3 epoch 150th train iter loss: 4.581225395202637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [04:05<46:18, 60.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 epoch ALL LOSS :  4.566077121754282\n",
      "New best model loss: 4.806483745574951\n",
      "best model is saved!\n",
      "4 epoch 0th train iter loss: 4.370638370513916\n",
      "4 epoch 50th train iter loss: 4.14817476272583\n",
      "4 epoch 100th train iter loss: 4.046624660491943\n",
      "4 epoch 150th train iter loss: 3.8190343379974365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [05:02<44:34, 59.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 epoch ALL LOSS :  4.0407752130449435\n",
      "New best model loss: 4.4406538009643555\n",
      "best model is saved!\n",
      "5 epoch 0th train iter loss: 3.7147114276885986\n",
      "5 epoch 50th train iter loss: 3.5322206020355225\n",
      "5 epoch 100th train iter loss: 3.5207626819610596\n",
      "5 epoch 150th train iter loss: 3.5813543796539307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [06:00<43:14, 58.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epoch ALL LOSS :  3.5607219959042737\n",
      "New best model loss: 4.105810880661011\n",
      "best model is saved!\n",
      "6 epoch 0th train iter loss: 3.175086498260498\n",
      "6 epoch 50th train iter loss: 3.257669448852539\n",
      "6 epoch 100th train iter loss: 3.1622731685638428\n",
      "6 epoch 150th train iter loss: 3.069887638092041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [06:58<41:52, 58.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 epoch ALL LOSS :  3.1287055740651395\n",
      "New best model loss: 3.7973544597625732\n",
      "best model is saved!\n",
      "7 epoch 0th train iter loss: 2.8347339630126953\n",
      "7 epoch 50th train iter loss: 2.926205635070801\n",
      "7 epoch 100th train iter loss: 2.7281014919281006\n",
      "7 epoch 150th train iter loss: 2.730452060699463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [07:56<40:45, 58.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 epoch ALL LOSS :  2.7422547217496893\n",
      "New best model loss: 3.5171594619750977\n",
      "best model is saved!\n",
      "8 epoch 0th train iter loss: 2.6433908939361572\n",
      "8 epoch 50th train iter loss: 2.329751491546631\n",
      "8 epoch 100th train iter loss: 2.428790330886841\n",
      "8 epoch 150th train iter loss: 2.471569061279297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [08:46<38:12, 55.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 epoch ALL LOSS :  2.400682845066503\n",
      "New best model loss: 3.2646350860595703\n",
      "best model is saved!\n",
      "9 epoch 0th train iter loss: 2.3468949794769287\n",
      "9 epoch 50th train iter loss: 2.202745199203491\n",
      "9 epoch 100th train iter loss: 2.1910617351531982\n",
      "9 epoch 150th train iter loss: 2.140113592147827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [09:32<35:10, 52.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 epoch ALL LOSS :  2.105957721926502\n",
      "New best model loss: 3.0398024320602417\n",
      "best model is saved!\n",
      "10 epoch 0th train iter loss: 1.96831214427948\n",
      "10 epoch 50th train iter loss: 1.9531030654907227\n",
      "10 epoch 100th train iter loss: 1.8480359315872192\n",
      "10 epoch 150th train iter loss: 1.8421456813812256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [10:18<32:57, 50.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 epoch ALL LOSS :  1.8546104320545787\n",
      "New best model loss: 2.843958258628845\n",
      "best model is saved!\n",
      "11 epoch 0th train iter loss: 1.7181956768035889\n",
      "11 epoch 50th train iter loss: 1.6331193447113037\n",
      "11 epoch 100th train iter loss: 1.645355224609375\n",
      "11 epoch 150th train iter loss: 1.6014100313186646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [11:04<31:09, 49.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 epoch ALL LOSS :  1.6453042472760702\n",
      "New best model loss: 2.671209931373596\n",
      "best model is saved!\n",
      "12 epoch 0th train iter loss: 1.5012619495391846\n",
      "12 epoch 50th train iter loss: 1.5185611248016357\n",
      "12 epoch 100th train iter loss: 1.4279882907867432\n",
      "12 epoch 150th train iter loss: 1.5627323389053345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [11:50<29:42, 48.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 epoch ALL LOSS :  1.47296129919819\n",
      "New best model loss: 2.5216702222824097\n",
      "best model is saved!\n",
      "13 epoch 0th train iter loss: 1.358162760734558\n",
      "13 epoch 50th train iter loss: 1.2669755220413208\n",
      "13 epoch 100th train iter loss: 1.3217434883117676\n",
      "13 epoch 150th train iter loss: 1.277565360069275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [12:36<28:29, 47.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 epoch ALL LOSS :  1.3338663713219239\n",
      "New best model loss: 2.395346999168396\n",
      "best model is saved!\n",
      "14 epoch 0th train iter loss: 1.273161768913269\n",
      "14 epoch 50th train iter loss: 1.166719675064087\n",
      "14 epoch 100th train iter loss: 1.2221766710281372\n",
      "14 epoch 150th train iter loss: 1.292030930519104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [13:21<27:23, 46.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 epoch ALL LOSS :  1.2214300890558774\n",
      "New best model loss: 2.2859179973602295\n",
      "best model is saved!\n",
      "15 epoch 0th train iter loss: 1.1753231287002563\n",
      "15 epoch 50th train iter loss: 1.0648599863052368\n",
      "15 epoch 100th train iter loss: 1.1364368200302124\n",
      "15 epoch 150th train iter loss: 1.1124370098114014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [14:07<26:23, 46.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 epoch ALL LOSS :  1.1316337861965613\n",
      "New best model loss: 2.195237159729004\n",
      "best model is saved!\n",
      "16 epoch 0th train iter loss: 1.0583091974258423\n",
      "16 epoch 50th train iter loss: 1.1070594787597656\n",
      "16 epoch 100th train iter loss: 1.090624451637268\n",
      "16 epoch 150th train iter loss: 1.0450598001480103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [14:52<25:25, 46.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 epoch ALL LOSS :  1.0590972040117401\n",
      "New best model loss: 2.1151498556137085\n",
      "best model is saved!\n",
      "17 epoch 0th train iter loss: 1.022923469543457\n",
      "17 epoch 50th train iter loss: 0.9845761656761169\n",
      "17 epoch 100th train iter loss: 0.9652628898620605\n",
      "17 epoch 150th train iter loss: 1.0085334777832031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [15:39<24:44, 46.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 epoch ALL LOSS :  1.0014024017397891\n",
      "New best model loss: 2.047707200050354\n",
      "best model is saved!\n",
      "18 epoch 0th train iter loss: 0.8904234766960144\n",
      "18 epoch 50th train iter loss: 0.9726393222808838\n",
      "18 epoch 100th train iter loss: 1.0106794834136963\n",
      "18 epoch 150th train iter loss: 0.9407221674919128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [16:25<23:51, 46.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 epoch ALL LOSS :  0.9543289834076596\n",
      "New best model loss: 1.9892476797103882\n",
      "best model is saved!\n",
      "19 epoch 0th train iter loss: 0.9483957886695862\n",
      "19 epoch 50th train iter loss: 0.9891787171363831\n",
      "19 epoch 100th train iter loss: 0.9553749561309814\n",
      "19 epoch 150th train iter loss: 0.9297745823860168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [17:10<22:59, 45.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 epoch ALL LOSS :  0.9166273502344938\n",
      "New best model loss: 1.9391127228736877\n",
      "best model is saved!\n",
      "20 epoch 0th train iter loss: 0.8811852931976318\n",
      "20 epoch 50th train iter loss: 0.8671367168426514\n",
      "20 epoch 100th train iter loss: 0.8970017433166504\n",
      "20 epoch 150th train iter loss: 0.883415699005127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [17:56<22:10, 45.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 epoch ALL LOSS :  0.8851652928848857\n",
      "New best model loss: 1.8967068791389465\n",
      "best model is saved!\n",
      "21 epoch 0th train iter loss: 0.8664023876190186\n",
      "21 epoch 50th train iter loss: 0.8384082317352295\n",
      "21 epoch 100th train iter loss: 0.8760558366775513\n",
      "21 epoch 150th train iter loss: 0.8502606749534607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [210:41:50<1768:17:15, 227351.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 epoch ALL LOSS :  0.85868137460394\n",
      "New best model loss: 1.8586407899856567\n",
      "best model is saved!\n",
      "22 epoch 0th train iter loss: 0.8228317499160767\n",
      "22 epoch 50th train iter loss: 0.8244432806968689\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "train_epoch_loss = []\n",
    "val_epoch_loss_lst = []\n",
    "best_val_epoch_loss = int(1e9)\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "  train_iter_loss = []\n",
    "  for i, values in enumerate(train_iter):\n",
    "    train_user = values[0].long().to(device)\n",
    "    train_item = values[1].long().to(device)\n",
    "    labels = values[2].to(device)\n",
    "    preds = model(train_user, train_item)\n",
    "    loss = loss_func(preds, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_iter_loss.append(loss.detach().item())\n",
    "    if i%50 == 0:\n",
    "      print(f'{epoch} epoch {i}th train iter loss: {loss.detach().item()}')  \n",
    "  train_epoch_loss.append(np.mean(train_iter_loss))\n",
    "  print(f'{epoch} epoch ALL LOSS : ', np.mean(train_iter_loss))\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    val_epoch_loss = 0\n",
    "    for i, values in enumerate(test_iter):\n",
    "      test_user = values[0].long().to(device)\n",
    "      test_item = values[1].long().to(device)\n",
    "      labels = values[2].to(device)\n",
    "      preds = model(test_user, test_item)\n",
    "      loss = loss_func(preds, labels)\n",
    "      val_epoch_loss += loss.detach().item()\n",
    "  val_epoch_loss /= len(test_iter)\n",
    "  val_epoch_loss_lst.append(val_epoch_loss)\n",
    "\n",
    "  if val_epoch_loss < best_val_epoch_loss:\n",
    "    best_val_epoch_loss = val_epoch_loss\n",
    "    print(f'New best model loss: {best_val_epoch_loss}')\n",
    "    if not os.path.exists('model'):\n",
    "      os.mkdir('model')\n",
    "\n",
    "    if os.path.exists('model/best.pth'):\n",
    "      os.remove('model/best.pth')\n",
    "    torch.save(model.state_dict(), 'model/best.pth')\n",
    "    print('best model is saved!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18710c84b20>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(val_epoch_loss_lst, label='train loss')\n",
    "\n",
    "plt.plot(train_epoch_loss, label='val loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.4434], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model(torch.tensor([20]).to(device), torch.tensor([20]).to(device))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93865c8914045f82f1cc4174d5a9f6658a56058b431eb3568707e1e9b23cbcf9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('bc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
