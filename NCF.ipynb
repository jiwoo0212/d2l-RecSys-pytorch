{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NCF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vz7AIinzizWy"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import zipfile\n",
        "from urllib import request\n",
        "\n",
        "def download_ml100k():\n",
        "    # download\n",
        "    url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "    savename = \"ml-100k.zip\"\n",
        "    request.urlretrieve(url, savename)\n",
        "    print('Complete!')\n",
        "    # unzip\n",
        "    file_name = os.path.join('./', savename)\n",
        "    file_zip = zipfile.ZipFile(file_name)\n",
        "    file_zip.extractall('./')\n",
        "    file_zip.close()\n",
        "\n",
        "def read_data_ml100k():\n",
        "    if not os.path.isfile(os.path.join('./ml-100k/', 'u.data')):\n",
        "        print('Download ...')\n",
        "        download_ml100k()\n",
        "    names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "    data = pd.read_csv(os.path.join('./ml-100k/', 'u.data'), '\\t', names=names,\n",
        "                       engine='python')\n",
        "    num_users = data.user_id.unique().shape[0]\n",
        "    num_items = data.item_id.unique().shape[0]\n",
        "    return data, num_users, num_items\n",
        "def load_data_ml100k(data, num_users, num_items, feedback='explicit'):\n",
        "    users, items, scores = [], [], []\n",
        "    inter = np.zeros((num_items, num_users)) if feedback == 'explicit' else {}\n",
        "    for line in data.itertuples():\n",
        "        user_index, item_index = int(line[1] - 1), int(line[2] - 1)\n",
        "        score = int(line[3]) if feedback == 'explicit' else 1\n",
        "        users.append(user_index)\n",
        "        items.append(item_index)\n",
        "        scores.append(score)\n",
        "        if feedback == 'implicit':\n",
        "            inter.setdefault(user_index, []).append(item_index)\n",
        "        else:\n",
        "            inter[item_index, user_index] = score\n",
        "    return users, items, scores, inter\n",
        "def split_data_ml100k(data, num_users, num_items,\n",
        "                      split_mode='random', test_ratio=0.1):\n",
        "    \"\"\"Split the dataset in random mode or seq-aware mode.\"\"\"\n",
        "    if split_mode == 'seq-aware':\n",
        "        train_items, test_items, train_list = {}, {}, []\n",
        "        for line in data.itertuples():\n",
        "            u, i, rating, time = line[1], line[2], line[3], line[4]\n",
        "            train_items.setdefault(u, []).append((u, i, rating, time))\n",
        "            if u not in test_items or test_items[u][-1] < time:\n",
        "                test_items[u] = (i, rating, time)\n",
        "        for u in range(1, num_users + 1):\n",
        "            train_list.extend(sorted(train_items[u], key=lambda k: k[3]))\n",
        "        test_data = [(key, *value) for key, value in test_items.items()]\n",
        "        train_data = [item for item in train_list if item not in test_data]\n",
        "        train_data = pd.DataFrame(train_data)\n",
        "        test_data = pd.DataFrame(test_data)\n",
        "    else:\n",
        "        mask = [True if x == 1 else False for x in np.random.uniform(\n",
        "            0, 1, (len(data))) < 1 - test_ratio]\n",
        "        neg_mask = [not x for x in mask]\n",
        "        train_data, test_data = data[mask], data[neg_mask]\n",
        "    return train_data, test_data"
      ],
      "metadata": {
        "id": "yUPx-n70m8zi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![NCF](https://d2l.ai/_images/rec-neumf.svg)"
      ],
      "metadata": {
        "id": "47tZJeB-jIwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "56Ii5RTZjdEj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuMF(nn.Module):\n",
        "\n",
        "    def __init__(self, num_factors, num_users, num_items, nums_hiddens, **kwargs):\n",
        "        super(NeuMF, self).__init__(**kwargs)\n",
        "        # 1. 임베딩 층\n",
        "        self.P = nn.Embedding(num_users, num_factors)\n",
        "        self.Q = nn.Embedding(num_items, num_factors)\n",
        "        self.U = nn.Embedding(num_users, num_factors)\n",
        "        self.V = nn.Embedding(num_items, num_factors)\n",
        "\n",
        "        # \b2. MLP 층\n",
        "        modules = []\n",
        "        for num_hiddens in nums_hiddens:\n",
        "          modules.append(nn.Linear(num_hiddens, activation='relu',\n",
        "                                  use_bias=True))\n",
        "        self.mlp = nn.Sequential(*modules)\n",
        "\n",
        "        # 3. prediction layer\n",
        "        self.prediction_layer = nn.Linear(1, activation='sigmoid', use_bias=False)\n",
        "\n",
        "    def forward(self, user_id, item_id):\n",
        "        p_mf = self.P(user_id)\n",
        "        q_mf = self.Q(item_id)\n",
        "        gmf = p_mf * q_mf\n",
        "        p_mlp = self.U(user_id)\n",
        "        q_mlp = self.V(item_id)\n",
        "        mlp = self.mlp(nn.concatenate([p_mlp, q_mlp], axis=1))\n",
        "        con_res = nn.concatenate([gmf, mlp], axis=1)\n",
        "        return self.prediction_layer(con_res)"
      ],
      "metadata": {
        "id": "Ymay18wgkP9l"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class PRDataset(Dataset):\n",
        "    def __init__(self, users, items, candidates, num_items):\n",
        "        self.users = users\n",
        "        self.items = items\n",
        "        self.cand = candidates\n",
        "        self.all = set([i for i in range(num_items)])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        neg_items = list(self.all - set(self.cand[int(self.users[idx])]))\n",
        "        indices = random.randint(0, len(neg_items) - 1)\n",
        "        return self.users[idx], self.items[idx], neg_items[indices]"
      ],
      "metadata": {
        "id": "MUrdXgzFmQAT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "df, num_users, num_items = read_data_ml100k()\n",
        "train_data, test_data = split_data_ml100k(df, num_users, num_items,\n",
        "                                              'seq-aware')\n",
        "users_train, items_train, ratings_train, candidates = load_data_ml100k(\n",
        "    train_data, num_users, num_items, feedback=\"implicit\")\n",
        "users_test, items_test, ratings_test, test_iter = load_data_ml100k(\n",
        "    test_data, num_users, num_items, feedback=\"implicit\")\n",
        "train_iter = DataLoader(\n",
        "    PRDataset(users_train, items_train, candidates, num_items ), batch_size,\n",
        "    True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF3R_ICUmwU1",
        "outputId": "9ad15480-5a7f-4363-dc11-ff982a422b34"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download ...\n",
            "Complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_iter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGYlO_I8nRKd",
        "outputId": "8a97b9b0-671a-44a0-c5fc-cc1189f8dac1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([329, 477, 499,  ..., 346,  43, 290]),\n",
              " tensor([ 79, 281,  99,  ..., 120,  70, 784]),\n",
              " tensor([ 856,  134, 1567,  ..., 1425, 1338, 1232])]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = NeuMF(10, num_users, num_items, nums_hiddens=[10, 10, 10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "KXHSHS-ZnXXH",
        "outputId": "31da98cb-ba2d-4622-9b2d-e7bb55809c63"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ab76074e9a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums_hiddens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-cdc862b3ab9d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_factors, num_users, num_items, nums_hiddens, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnum_hiddens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnums_hiddens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           modules.append(nn.Linear(num_hiddens, activation='relu',\n\u001b[0;32m---> 15\u001b[0;31m                                   use_bias=True))\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'activation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g64BIwrmnf0N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}